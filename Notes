Notes for pandas-myutils module


idx_toggle_multi()
	Test cases
		Add more tests so that we can test the most common occurences, such as after reading json data into pandas.

		For instance, the case where we have a MultiIndex with empty strings in level values is quite common and we test that one, but test any variations I encounter in practice.

	Option to add level names?
		Should we add a boolean option e.g. add_names= or is this best level to the user?
			new_idx.names = ['level1', 'level2', 'etc']

		If we add that option what what would be the best default value, True or False?

	propagate=False
		I added this option in 2023 dec, after about 6+ months of using the module in my hockey parsers.

		What should be the default?
			I chose True because the purpose of the module is to be a convenience and the most frequent use I have for it -- at least at this time -- is to propagate levels.
			That comes at the expense of coding legibility, simplicity, as it peppers the code with a few conditions that can make the code slightly difficult to understand -- I prefer to do-one-thing-and-do-it-well but, in this case, convenience is important. I can mitigate this by having a clear testing suite and judicious use of comments and design notes.

			If I ever do change the default to False, make sure I check all my parsers and modules that use it to ensure that wouldn't break anything.


convert_to_integer()
	Maximum values
		not a concern, maximum values or integers can be crazy huge (google it)

	arrow=True
		allow converting to int64 (not pyarrow) if set to False

	Consider making this function more general i.e. if the data is arrow, convert to arrow integer, if it isn't convert to "normal" integers (would automatically exclude cols that have nulls, I could add a para i.e. convert_to_arrow=True with a default of False).
		Well it's a bit more complicated than that. I often want to use this function to convert int64 (not arrow) columns. Besides as it currently now stands in pandas, there is no such things as a pyarrow df. A df can have a mix of arrow dtypes and non-arrow. So I should probably just add an arrow parameter that defaults to True to convert the data, including int64 to int64[pyarrow] dtype.


convert_to_arrow()
	A function to convert all columns to arrow since there is currently no way (that I see as of spring 2024) to have newly created columns be arrow ones unless we explicitly set as type -- which I don't want to do.

	This function is quite limited to specifc types we are listing in dtype_mapping = {}
		we should add to this list -- albeit, the need for this function is quite temporary until pyarrow becomes fully implemented and the default, so no need to go overboard in coding this one.


Testing
	python -m pytest -v --setup-show
	python -m pytest test/test_main.py
	python -m pytest -v --setup-show test/test_main.py

	In the debugger:
		python -m pdb -m pytest
		python -m pdb -m pytest test/test_main.py
		python -m pdb -m pytest -v --setup-show test/test_main.py


Installing
	python -m pip install .


Documentation
	pydoc pandas_myutils.utils
